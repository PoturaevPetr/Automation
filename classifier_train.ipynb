{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194e927",
   "metadata": {
    "cellId": "f33g5a6iipq8wlhgha02"
   },
   "outputs": [],
   "source": [
    "# Импорт зависимостей\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996ddaa",
   "metadata": {
    "cellId": "3nspu9k2o1lm2szl6r0nm8"
   },
   "outputs": [],
   "source": [
    "#Путь к папкам с данными для обучения\n",
    "\"\"\"\n",
    "В папках (train, val) должны находиться папки, имя которых - название класса\n",
    "пример:\n",
    "/train\n",
    "    - /cats\n",
    "    - /dogs\n",
    "/val\n",
    "    - /cats\n",
    "    - /dogs\n",
    "Количество данных в обучающей выборке может быть неравномерным\n",
    "В валидационной выборке как правило делают равномерное распределение (к примеру,по 50 снимков на класс)\n",
    "\"\"\"\n",
    "dataset_folder = \"dataset_learn_steel_mark\"\n",
    "train_dir = f\"datasets/{dataset_folder}/train\"\n",
    "val_dir = f\"datasets/{dataset_folder}/valid\"\n",
    "test_dir = f\"datasets/{dataset_folder}/test\"\n",
    "\n",
    "# Размер изображения для вохдного тензора нейросети (см. документацию по НС https://www.tensorflow.org/api_docs/python/tf/keras/applications)\n",
    "\"\"\"Если при обучении используются предобученные веса (imagenet...), то размер входного тензора должен соответсвовать весам\"\"\"\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Входной тензор\n",
    "input_shape = (img_width, img_height,3)\n",
    "\n",
    "# Количество классов для обучения\n",
    "num_classes = 5\n",
    "\n",
    "# Количество эпох обучения\n",
    "epochs = 50\n",
    "\n",
    "# Количество изображений, которые будут подаваться НС при одной итерации обучения\n",
    "batch_size = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f089e3c",
   "metadata": {
    "cellId": "ul8u0ei553yjd2dwfi0f"
   },
   "outputs": [],
   "source": [
    "model_name = \"VGG16\"\n",
    "\n",
    "if model_name == \"MobileNet\":\n",
    "    base_model = tf.keras.applications.MobileNet(\n",
    "        input_shape=(img_width, img_height, 3),\n",
    "        include_top=False, #True\n",
    "        weights='imagenet',\n",
    "        classes=num_classes,\n",
    "    )\n",
    "if model_name == \"VGG16\":\n",
    "    base_model = tf.keras.applications.VGG16(\n",
    "        input_shape=(img_width, img_height, 3),\n",
    "        include_top=False, #True\n",
    "        weights='imagenet',\n",
    "        classes=num_classes,\n",
    "    )\n",
    "# Включаем переобучение основной модели\n",
    "base_model.trainable = True\n",
    "# Добавляем слои полносвязного слоя в модель\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GlobalAveragePooling2D(name='global_average_pooling2d'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax', name='predictions'))\n",
    "\n",
    "\n",
    "\n",
    "for cnn_block_layer in model.layers[0].layers:\n",
    "   cnn_block_layer.trainable = True\n",
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6046c2",
   "metadata": {
    "cellId": "1i9ihj2x70aahxfiqh1k7c"
   },
   "outputs": [],
   "source": [
    "# Скорость обучения НС \n",
    "\"\"\"\n",
    "Если несколько эпох подряд на старте обучения получаются одинаковые значения точности примерно равные доле от 100/количество классов\n",
    "Например: при 3 классах точность держится в районе 0.33\n",
    "https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\n",
    "\"\"\"\n",
    "learning_rate = 0.00001\n",
    "# Параметры специфичные для оптимизатора SGD \n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "# Другие оптимизаторы https://keras.io/api/optimizers/\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=True)\n",
    "# Компиляция модели\n",
    "\"\"\"\n",
    "Функции потерь: https://keras.io/api/losses/\n",
    "Метрики точности: https://keras.io/api/metrics/\n",
    "\"\"\"\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd, \n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83c227",
   "metadata": {
    "cellId": "uw2wjxligi63pbcf5h4jm"
   },
   "outputs": [],
   "source": [
    "# Вывод структуры полученной модели\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b69e03",
   "metadata": {
    "cellId": "k2h4ekpelgd4tvyhrnqq34"
   },
   "outputs": [],
   "source": [
    "# Генератор данных \n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1. / 255, \n",
    "    validation_split=0,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "cpt_dir = f\"chkpt/{dataset_folder}/{model_name}/lr-{learning_rate}_m-{momentum}\"\n",
    "report_dir = f\"reports/{dataset_folder}/{model_name}/lr-{learning_rate}_m-{momentum}\"\n",
    "os.makedirs(report_dir, exist_ok=True)\n",
    "def replace_ints(arr, labels):\n",
    "    result = []\n",
    "    for i in arr:\n",
    "        result.append(labels[i])\n",
    "    return result\n",
    "\n",
    "def make_report(y_test, y_pred, classes):\n",
    "    #Generate the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(10,8))  \n",
    "    ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "    ax.set_title('Confusion Matrix\\n')\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ')\n",
    "\n",
    "  ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(classes)\n",
    "    ax.yaxis.set_ticklabels(classes)\n",
    "    plt.savefig(str(report_dir) + '/confusion_matrix.png')\n",
    "  ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "    target_names = classes\n",
    "    report = classification_report(y_test,y_pred,target_names=target_names)\n",
    "    print(report)\n",
    "    with open(f'{report_dir}/classification_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "\n",
    "    y_test = label_binarize(y_test, classes=classes)\n",
    "    y_pred = label_binarize(y_pred, classes=classes)\n",
    "    n_classes = y_pred.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    colors = cycle(['blue', 'red', 'green'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=1.5,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(classes[i], roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for multi-class data')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(str(report_dir) + '/roc_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, checkpointer):\n",
    "        super().__init__()\n",
    "        self.checkpointer = checkpointer\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('categorical_accuracy'))\n",
    "        self.val_acc.append(logs.get('val_categorical_accuracy'))\n",
    "        self.i += 1\n",
    "        print('i=', self.i,\n",
    "              'loss=', logs.get('loss'),\n",
    "              'val_loss=', logs.get('val_loss'),\n",
    "              'categorical_accuracy=', logs.get('categorical_accuracy'),\n",
    "              'val_categorical_accuracy=', logs.get('val_categorical_accuracy'))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # Построение графиков\n",
    "        fig, axs = plt.subplots(figsize=(12, 6))  \n",
    "\n",
    "        axs.plot(self.x, self.acc, marker='o', ms=4, label=\"Train\")\n",
    "        axs.plot(self.x, self.val_acc, marker='o', ms=4, label=\"Validation\")\n",
    "        axs.set_xlabel(\"Epochs, Num\")\n",
    "        axs.legend()\n",
    "        axs.set_ylabel(\"Value Accuracy, %\")\n",
    "        axs.set_xticks(np.arange(min(self.x), max(self.x)+1, 10.0))\n",
    "        axs.grid()\n",
    "        plt.savefig(str(report_dir) + '/train_accuracy.png')\n",
    "        plt.show()\n",
    "\n",
    "        fig, axs = plt.subplots(figsize=(12, 6))  \n",
    "        axs.plot(self.x, self.losses, marker='o', ms=4, label=\"Train\")\n",
    "        axs.plot(self.x, self.val_losses, marker='o', ms=4, label=\"Validation\")\n",
    "        axs.set_xlabel(\"Epochs, Num\")\n",
    "        axs.legend()\n",
    "        axs.set_ylabel(\"Value Loss, %\")\n",
    "        axs.set_xticks(np.arange(min(self.x), max(self.x)+1, 10.0))\n",
    "        axs.grid()\n",
    "        plt.savefig(str(report_dir) + '/train_loss.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Сохранение данных в CSV\n",
    "        data = {\n",
    "            'epochs': self.x,\n",
    "            'train_acc': self.acc,\n",
    "            'val_acc': self.val_acc,\n",
    "            'train_loss': self.losses,\n",
    "            'valid_loss': self.val_losses\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(str(report_dir) + '/learn.csv')\n",
    "        ckpt_list = os.listdir(cpt_dir)\n",
    "        print(\"BEST MODEL\", ckpt_list[-1])\n",
    "        weights_path = f\"{cpt_dir}/{ckpt_list[-1]}\"\n",
    "        img_width, img_height = 224, 224\n",
    "        \n",
    "        classes =[item.replace(\"_\", \" \").title() for item in os.listdir(test_dir) if item != \".DS_Store\"]\n",
    "        num_classes = len(classes)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_generator = test_datagen.flow_from_directory(\n",
    "                test_dir,\n",
    "                target_size=(img_width, img_height),\n",
    "                color_mode=\"rgb\",\n",
    "                shuffle = False,\n",
    "                class_mode='categorical',\n",
    "                batch_size=1)\n",
    "        model.load_weights(weights_path)\n",
    "        filenames = test_generator.filenames\n",
    "        nb_samples = len(filenames)\n",
    "        predict = model.predict(test_generator,steps = nb_samples)\n",
    "        make_report(replace_ints(np.array(test_generator.classes), classes),replace_ints(np.argmax(predict, axis=1), classes), classes = classes)\n",
    "\n",
    "# Создайте коллбэки, передав checkpointer\n",
    "def build_callbacks():\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "        cpt_dir + '/{epoch:02d}_acc_{val_categorical_accuracy:.2f}.h5',\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=True,\n",
    "        save_best_only=True\n",
    "    )\n",
    "    plot_learning = PlotLearning(checkpointer)\n",
    "    return [checkpointer, plot_learning], checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a60d8e",
   "metadata": {
    "cellId": "rvol2ko73kd7t76ue3t2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Директория, в которую будут сохраняться лучшие эпохи обучения\n",
    "  \n",
    "# Балансировка весов в обучающей выборке при помощи пакета sklearn\n",
    "\"\"\"\n",
    "Балансировка весов помогает избежать \"перевеса\" НС в сторону одного из классов при неравномерном распределении количества данных в разных классах\n",
    "\"\"\"\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "# Приведение к необходимому формату\n",
    "class_weights = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "print(class_weights)\n",
    "# import pydotplus\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model_fvsdfg.png', show_shapes=True)\n",
    "\"\"\"Запуск обучения НС\"\"\"\n",
    "histoty = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator.filenames) // batch_size,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[build_callbacks()]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "notebookId": "8b186155-e94d-4a95-8b61-bb125e5b1cec",
  "notebookPath": "ForStudents.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
